{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EbF599vv5UQm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "840f6dda-48bf-4c42-f42e-a09710cb6a13"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-95468606606d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 124\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip "
      ],
      "metadata": {
        "id": "FLFZ8PJy1kdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install fire\n",
        "#!pip install tensorboardX\n",
        "#!pip install prdc\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from copy import deepcopy\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST, CIFAR10, CelebA, SVHN\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils import data\n",
        "\n",
        "import warnings\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "from scipy import linalg\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import inception_v3, vgg16\n",
        "from prdc import compute_prdc\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import cv2\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad\n",
        "from tensorboardX import SummaryWriter\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import fire"
      ],
      "metadata": {
        "id": "26AGXZR07p1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "Ol9BerIA8zzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NextDataLoader(data.DataLoader):\n",
        "    def __next__(self):\n",
        "        try:\n",
        "            return next(self.iterator)\n",
        "        except:\n",
        "            self.iterator = self.__iter__()\n",
        "            return next(self.iterator)"
      ],
      "metadata": {
        "id": "A5ze8Slg7-dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cifardata(batch_size, num_workers):\n",
        "    transform = transforms.Compose([\n",
        "                                    # transforms.Resize(28),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                  ])\n",
        "    dataset = CIFAR10('data/cifar_data', transform=transform, download=True)\n",
        "    dataloader = NextDataLoader(dataset, batch_size=batch_size, num_workers=num_workers)\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "def svhndata(batch_size, num_workers):\n",
        "    transform = transforms.Compose([\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                  ])\n",
        "    dataset = SVHN('data/svhn_data', transform=transform, download=True)\n",
        "    dataloader = NextDataLoader(dataset, batch_size=batch_size, num_workers=num_workers)\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "def celebdata(batch_size, num_workers):\n",
        "    print('Loading data...')\n",
        "    transform = transforms.Compose([\n",
        "                                        transforms.Resize(128),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                    ])\n",
        "    dataset = ImageFolder('data/celeba_hq/train', transform=transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    print('Data loaded.')\n",
        "    return dataloader\n"
      ],
      "metadata": {
        "id": "ag7N6JaH7_B8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PixelNorm(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PixelNorm, self).__init__()\n",
        "        self.epsilon = 1e-8\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x / torch.sqrt((torch.mean(x ** 2, dim=1, keepdim=True) + self.epsilon))\n",
        "\n",
        "\n",
        "class InjectNoise(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x, image_noise=None):\n",
        "        if image_noise is None:\n",
        "            input_noise = torch.randn(x.shape[0], 1, x.shape[2], x.shape[3], device=x.device)\n",
        "        noise = self.weight * input_noise\n",
        "        return x + noise\n",
        "\n",
        "\n",
        "class MiniBatchSD(nn.Module):\n",
        "    def __init__(self, group_size=4):\n",
        "        super(MiniBatchSD, self).__init__()\n",
        "        self.group_size = group_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        s = x.shape\n",
        "        t = x.view(self.group_size, -1, s[1], s[2], s[3])\n",
        "        t = t - t.mean(dim=0, keepdim=True)\n",
        "        t = torch.sqrt((t ** 2).mean(dim=0) + 1e-8)\n",
        "        t = t.mean(dim=[1, 2, 3], keepdim=True)  # [N/G,1,1,1]\n",
        "        t = t.repeat(self.group_size, 1, 1, 1).expand(x.shape[0], 1, *x.shape[2:])\n",
        "        return torch.cat((x, t), dim=1)\n",
        "\n",
        "\n",
        "class ConvModulated(nn.Conv2d):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, latent_size,\n",
        "                 demodulate=True, bias=True, stride=1, padding=0, dilation=1, **kwargs):\n",
        "        super().__init__(in_channels, out_channels, kernel_size, stride,\n",
        "                         padding, dilation, groups=1,\n",
        "                         bias=bias, padding_mode='zeros')\n",
        "        self.demodulate = demodulate\n",
        "\n",
        "        self.style = nn.Linear(latent_size, in_channels)\n",
        "\n",
        "        self.s_broadcast_view = (-1, 1, self.in_channels, 1, 1)\n",
        "        self.in_channels_dim = 2\n",
        "\n",
        "    def convolve(self, x, w, groups):\n",
        "\n",
        "        return F.conv2d(x, w, None, self.stride, self.padding, self.dilation, groups=groups)\n",
        "\n",
        "    def forward(self, x, v):\n",
        "        N, in_channels, H, W = x.shape\n",
        "        w = self.weight.unsqueeze(0)\n",
        "        s = self.style(v) + 1\n",
        "        w = s.view(self.s_broadcast_view) * w\n",
        "\n",
        "        if self.demodulate:\n",
        "            sigma = torch.sqrt((w ** 2).sum(dim=[self.in_channels_dim, 3, 4], keepdim=True) + 1e-8)\n",
        "            w = w / sigma\n",
        "\n",
        "        x = x.view(1, -1, H, W)\n",
        "        w = w.view(-1, w.shape[2], w.shape[3], w.shape[4])\n",
        "        out = self.convolve(x, w, N)\n",
        "        out = out.view(N, -1, out.shape[2], out.shape[3])\n",
        "\n",
        "        if not self.bias is None:\n",
        "            out += self.bias.view(1, self.bias.shape[0], 1, 1)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Up_Mod_Conv(ConvModulated):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, latent_size,\n",
        "                 demodulate=True, bias=True, factor=2):\n",
        "        assert (kernel_size % 2 == 1)\n",
        "        padding = (max(kernel_size - factor, 0) + 1) // 2\n",
        "        super().__init__(in_channels, out_channels, kernel_size, latent_size, demodulate, bias,\n",
        "                         stride=factor, padding=padding)\n",
        "        self.output_padding = torch.nn.modules.utils._pair(2 * padding - kernel_size + factor)\n",
        "        # transpose as expected in F.conv_transpose2d\n",
        "        self.weight = nn.Parameter(self.weight.transpose(0, 1).contiguous())\n",
        "        self.transposed = True\n",
        "        # taking into account transposition\n",
        "        self.s_broadcast_view = (-1, self.in_channels, 1, 1, 1)\n",
        "        self.in_channels_dim = 1\n",
        "\n",
        "    def convolve(self, x, w, groups):\n",
        "        return F.conv_transpose2d(x, w, None, self.stride, self.padding, self.output_padding, groups, self.dilation)\n",
        "\n",
        "\n",
        "class Down_Conv2d(nn.Conv2d):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 bias=True, factor=2):\n",
        "        assert (kernel_size % 2 == 1)\n",
        "        padding = kernel_size // 2\n",
        "        super().__init__(in_channels, out_channels, kernel_size, factor, padding, bias=True)\n",
        "\n",
        "    def convolve(self, x, w):\n",
        "        return F.conv2d(x, w, None, self.stride, self.padding, self.dilation, self.groups)\n",
        "\n",
        "\n",
        "class Equalized_Linear:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def compute_norm(module, weight):\n",
        "        mode = 'fan_in'\n",
        "        if hasattr(module, 'transposed') and module.transposed:\n",
        "            mode = 'fan_out'\n",
        "        return torch.nn.init._calculate_correct_fan(weight, mode)\n",
        "\n",
        "    def scale_weight(self, module, input):\n",
        "        setattr(module, self.name, module.scale * module.weight_orig)\n",
        "\n",
        "    def fn(self, module):\n",
        "        try:\n",
        "            weight = getattr(module, self.name)\n",
        "            module.scale = 1 / np.sqrt(Equalized_Linear.compute_norm(module, weight))\n",
        "            if isinstance(weight, torch.nn.Parameter):\n",
        "                # register new parameter -- unscaled weight\n",
        "                module.weight_orig = nn.Parameter(weight.clone() / module.scale)\n",
        "                # delete old parameter\n",
        "                del module._parameters[self.name]\n",
        "            else:\n",
        "                # register new buffer -- unscaled weight\n",
        "                module.register_buffer('weight_orig', weight.clone() / module.scale)\n",
        "                # delete old buffer\n",
        "                del module._buffers[self.name]\n",
        "            module.equalize = module.register_forward_pre_hook(self.scale_weight)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    def __call__(self, module):\n",
        "        new_module = deepcopy(module)\n",
        "        new_module.apply(self.fn)\n",
        "        return new_module\n",
        "\n",
        "\n",
        "def parameters_to_buffers(m):\n",
        "    params = m._parameters.copy()\n",
        "    m._parameters.clear()\n",
        "    for n, p in params.items():\n",
        "        m.register_buffer(n, p.data)\n"
      ],
      "metadata": {
        "id": "lFRLchhS7qem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GeneratorBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, kernel_size, latent_size, factor=2, img_channels=3):\n",
        "        super().__init__()\n",
        "        inter_fmaps = (in_channel + out_channel)//2\n",
        "        self.upconv = Up_Mod_Conv(in_channel, inter_fmaps, kernel_size, latent_size,\n",
        "                                      factor=factor)\n",
        "        self.conv = ConvModulated(inter_fmaps, out_channel, kernel_size, latent_size,\n",
        "                                     padding=kernel_size//2)\n",
        "        self.noise = InjectNoise()\n",
        "        self.noise2 = InjectNoise()\n",
        "        self.to_channels = ConvModulated(out_channel, img_channels, kernel_size=1,\n",
        "                                      latent_size=latent_size, demodulate = False)\n",
        "        self.upsample = nn.Upsample(scale_factor=factor, mode='bilinear', align_corners=False)\n",
        "        self.act = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x, w, y=None, input_noises=None):\n",
        "        x = self.noise(self.upconv(x, w), None if (input_noises is None) else input_noises[:,0])\n",
        "        x = self.act(x)\n",
        "        x = self.noise2(self.conv(x, w), None if (input_noises is None) else input_noises[:,1])\n",
        "        x = self.act(x)\n",
        "        if not y is None:\n",
        "            y = self.upsample(y)\n",
        "        else:\n",
        "            y = 0\n",
        "        y = y + self.to_channels(x,w)\n",
        "        return x, y\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, kernel_size, latent_size, style_depth, img_channels,\n",
        "                 min_res, max_res, blocks, style_mixing_prob=0.8, dlatent_avg_beta=0.995, weights_avg_beta=0.99):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        dres = min_res * 2 ** blocks - max_res\n",
        "        assert dres >= 0\n",
        "        self.latent_size = latent_size\n",
        "        layers = [PixelNorm()]\n",
        "        for i in range(style_depth):\n",
        "            layer = nn.Linear(latent_size, latent_size)\n",
        "            self.add_module(str(i), layer)\n",
        "            layers.append(layer)\n",
        "            layers.append(nn.LeakyReLU(0.2))\n",
        "        self.mapping_network = nn.Sequential(*layers)\n",
        "        self.const = nn.Parameter(torch.randn(out_channel, min_res, min_res))\n",
        "        fmaps = np.linspace(out_channel, in_channel, blocks + 1).astype('int')\n",
        "        self.layers = []\n",
        "        for i in range(blocks):\n",
        "            layer = GeneratorBlock(fmaps[i], fmaps[i + 1], kernel_size, latent_size, img_channels=img_channels)\n",
        "            self.add_module(str(i), layer)\n",
        "            self.layers.append(layer)\n",
        "        if dres > 0:\n",
        "            self.crop = torch.nn.ZeroPad2d(-dres // 2)\n",
        "        self.style_mixing_prob = style_mixing_prob\n",
        "        self.dlatent_avg_beta = dlatent_avg_beta\n",
        "        self.register_buffer('dlatent_avg', torch.zeros(latent_size))\n",
        "        self.weights_avg_beta = weights_avg_beta\n",
        "        self.Src_Net = deepcopy(self).apply(parameters_to_buffers)\n",
        "        self.Src_Net.train(False)\n",
        "\n",
        "    def update_avg_weights(self):\n",
        "        params = dict(self.named_parameters())\n",
        "        buffers = dict(self.named_buffers())\n",
        "        for n, b in self.Src_Net.named_buffers():\n",
        "            try:\n",
        "                b.data.copy_(self.weights_avg_beta * b + (1 - self.weights_avg_beta) * params[n])\n",
        "            except:\n",
        "                b.data.copy_(buffers[n])\n",
        "\n",
        "    def load_avg_weights(self):\n",
        "        buffers = dict(self.Src_Net.named_buffers())\n",
        "        for n, p in self.named_parameters():\n",
        "            p.data.copy_(buffers[n])\n",
        "\n",
        "    def sample_dlatents(self, n):\n",
        "        z = torch.randn(n, self.latent_size)\n",
        "        v = self.mapping_network(z)\n",
        "        if self.training:\n",
        "            self.dlatent_avg = self.dlatent_avg_beta * self.dlatent_avg + (1 - self.dlatent_avg_beta) * v.data.mean(0)\n",
        "        if self.training and self.style_mixing_prob > 0:\n",
        "            v = v.unsqueeze(1).expand(-1, len(self.layers), -1)\n",
        "            l = len(self.layers)\n",
        "            cut_off = torch.randint(l - 1, ())\n",
        "            v2 = torch.randn(n, self.latent_size)\n",
        "            v2 = self.mapping_network(v2)\n",
        "            if self.training:\n",
        "              self.dlatent_avg = self.dlatent_avg_beta * self.dlatent_avg + (1 - self.dlatent_avg_beta) * v2.data.mean(0)\n",
        "            v2 = v2.unsqueeze(1).expand(-1, len(self.layers), -1)\n",
        "            mask = torch.empty(n, dtype=torch.bool).bernoulli_(self.style_mixing_prob).view(-1, 1) \\\n",
        "                    * (torch.arange(l) > cut_off)\n",
        "            v = torch.where(mask.unsqueeze(-1).to(device=v.device), v2, v)\n",
        "        return v\n",
        "\n",
        "    def generate(self, v, input_noises=None):\n",
        "        x = self.const.expand(v.shape[0], *self.const.shape).contiguous()\n",
        "        input_noises = input_noises if input_noises else [None] * len(self.layers)\n",
        "        y = None\n",
        "        if v.ndim < 3:\n",
        "            v = v.unsqueeze(1).expand(-1, len(self.layers), -1)\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            x, y = layer(x, v[:, i], y, input_noises[i])\n",
        "        if hasattr(self, 'crop'):\n",
        "            y = self.crop(y)\n",
        "        return y\n",
        "\n",
        "    def sample(self, n):\n",
        "        dlatents = self.sample_dlatents(n)\n",
        "        x = self.generate(dlatents)\n",
        "        return x\n",
        "\n",
        "    def sample_images(self, n, truncation_psi=1):\n",
        "        with torch.no_grad():\n",
        "            v = self.Src_Net.sample_dlatents(n)\n",
        "            if truncation_psi < 1:\n",
        "                v = self.dlatent_avg + truncation_psi * (v - self.dlatent_avg)\n",
        "            images = self.Src_Net.generate(v)\n",
        "        return images\n",
        "\n",
        "\n",
        "class DiscriminatorBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, kernel_size, factor=2):\n",
        "        super().__init__()\n",
        "        inter_fmaps = (in_channel + out_channel)//2\n",
        "        self.conv = nn.Conv2d(in_channel, inter_fmaps, kernel_size, padding=kernel_size//2)\n",
        "        self.downconv = Down_Conv2d(inter_fmaps, out_channel, kernel_size, factor=factor)\n",
        "        self.skip = Down_Conv2d(in_channel, out_channel, kernel_size=1, factor=factor)\n",
        "        self.act = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        t = x\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = self.downconv(x)\n",
        "        x = self.act(x)\n",
        "        t = self.skip(t)\n",
        "        return (x + t)/ np.sqrt(2)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, kernel_size, blocks, img_channels, min_res, max_res, dense_size=128 ):\n",
        "        super(Discriminator, self).__init__()\n",
        "        assert min_res * 2 ** blocks >= max_res >= (min_res - 1) * 2 ** blocks\n",
        "        fmaps = np.linspace(in_channel, out_channel, blocks + 1).astype('int')\n",
        "        self.from_channels = nn.Conv2d(img_channels, fmaps[0], 1)\n",
        "        self.layers = []\n",
        "        for i in range(blocks):\n",
        "            layer = DiscriminatorBlock(fmaps[i], fmaps[i + 1], kernel_size)\n",
        "            self.add_module(str(i), layer)\n",
        "            self.layers.append(layer)\n",
        "        self.minibatch_sttdev = MiniBatchSD()\n",
        "        self.conv = nn.Conv2d(fmaps[-1] + 1, fmaps[-1], 3)\n",
        "        self.dense = nn.Linear(fmaps[-1] * (min_res - 2) ** 2, dense_size)\n",
        "        self.output = nn.Linear(dense_size, 1)\n",
        "        self.act = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def get_score(self, imgs):\n",
        "        x = self.act(self.from_channels(imgs))\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        x = self.minibatch_sttdev(x)\n",
        "        x = self.act(self.conv(x))\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.act(self.dense(x))\n",
        "        x = self.output(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "B9jN75jP7upA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def device(ngpu):\n",
        "    dev = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "    return dev"
      ],
      "metadata": {
        "id": "J8m-Ohn28axx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngpu = 0\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu>0) else \"cpu\")\n",
        "\n",
        "\n",
        "class EvaluationMetric:\n",
        "    def __init__(self, transform_input=True):\n",
        "        self.transform_input = transform_input\n",
        "        self.InceptionV3 = inception_v3(pretrained=True, transform_input=False)\n",
        "        self.InceptionV3.eval()\n",
        "        self.k = 3\n",
        "\n",
        "    def evaluate(self, real_img, generated_img):\n",
        "        mu1, sigma1, mu2, sigma2, precision, recall  = self.calc_activation_stats(real_img, generated_img)\n",
        "        fid = self.compute_fid(mu1, sigma1, mu2, sigma2)\n",
        "        #precision, recall = self.compute_prec_recall()\n",
        "\n",
        "        print('FID:', fid)\n",
        "        print('Precision:', precision)\n",
        "        print('Recall:', recall)\n",
        "\n",
        "    def build_maps(self, x):\n",
        "        if list(x.shape[-2:]) != [299, 299]:\n",
        "            with warnings.catch_warnings():\n",
        "                warnings.simplefilter(\"ignore\")\n",
        "                x = F.interpolate(x, size=[299, 299], mode='bilinear')\n",
        "        if self.transform_input:\n",
        "            x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
        "            x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
        "            x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
        "            x = torch.cat((x_ch0, x_ch1, x_ch2), 1)\n",
        "        with torch.no_grad():\n",
        "            x = self.InceptionV3.Conv2d_1a_3x3(x)\n",
        "            x = self.InceptionV3.Conv2d_2a_3x3(x)\n",
        "            x = self.InceptionV3.Conv2d_2b_3x3(x)\n",
        "            x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "            x = self.InceptionV3.Conv2d_3b_1x1(x)\n",
        "            x = self.InceptionV3.Conv2d_4a_3x3(x)\n",
        "            x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "            x = self.InceptionV3.Mixed_5b(x)\n",
        "            x = self.InceptionV3.Mixed_5c(x)\n",
        "            x = self.InceptionV3.Mixed_5d(x)\n",
        "            x = self.InceptionV3.Mixed_6a(x)\n",
        "            x = self.InceptionV3.Mixed_6b(x)\n",
        "            x = self.InceptionV3.Mixed_6c(x)\n",
        "            x = self.InceptionV3.Mixed_6d(x)\n",
        "            x = self.InceptionV3.Mixed_6e(x)\n",
        "            x = self.InceptionV3.Mixed_7a(x)\n",
        "            x = self.InceptionV3.Mixed_7b(x)\n",
        "            x = self.InceptionV3.Mixed_7c(x)\n",
        "            x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "            return x\n",
        "\n",
        "    def compute_fid(self, mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
        "        mu1 = np.atleast_1d(mu1)\n",
        "        mu2 = np.atleast_1d(mu2)\n",
        "\n",
        "        sigma1 = np.atleast_2d(sigma1)\n",
        "        sigma2 = np.atleast_2d(sigma2)\n",
        "\n",
        "        assert mu1.shape == mu2.shape, \\\n",
        "            'Training and test mean vectors have different lengths'\n",
        "        assert sigma1.shape == sigma2.shape, \\\n",
        "            'Training and test covariances have different dimensions'\n",
        "\n",
        "        diff = mu1 - mu2\n",
        "\n",
        "        covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
        "        if not np.isfinite(covmean).all():\n",
        "            msg = ('fid calculation produces singular product; '\n",
        "                   'adding %s to diagonal of cov estimates') % eps\n",
        "            print(msg)\n",
        "            offset = np.eye(sigma1.shape[0]) * eps\n",
        "            covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
        "\n",
        "        if np.iscomplexobj(covmean):\n",
        "            if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
        "                m = np.max(np.abs(covmean.imag))\n",
        "                raise ValueError('Imaginary component {}'.format(m))\n",
        "            covmean = covmean.real\n",
        "\n",
        "        tr_covmean = np.trace(covmean)\n",
        "\n",
        "        return diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean\n",
        "\n",
        "    def calc_activation_stats(self, real_img, generated_img, batch_size=64):\n",
        "\n",
        "        assert real_img.shape[0] == generated_img.shape[0]\n",
        "        real_images = real_img[np.random.permutation(real_img.shape[0])]\n",
        "\n",
        "        generated_images = generated_img[np.random.permutation(generated_img.shape[0])]\n",
        "        nearest_k = 3\n",
        "        real_maps = []\n",
        "        generated_maps = []\n",
        "        for s in range(int(math.ceil(real_images.shape[0] / batch_size))):\n",
        "            sidx = np.arange(batch_size * s, min(batch_size * (s + 1), real_images.shape[0]))\n",
        "            real_maps.append(self.build_maps(real_images[sidx]).detach().to(device=device))\n",
        "            generated_maps.append(\n",
        "                self.build_maps(generated_images[sidx]).detach().to(device=device))\n",
        "\n",
        "        real_maps = np.squeeze(torch.cat(real_maps).numpy())\n",
        "        generated_maps = np.squeeze(torch.cat(generated_maps).numpy())\n",
        "\n",
        "        mu1 = np.mean(generated_maps, axis=0)\n",
        "        mu2 = np.mean(real_maps, axis=0)\n",
        "        sigma1 = np.cov(generated_maps, rowvar=False)\n",
        "        sigma2 = np.cov(real_maps, rowvar=False)\n",
        "        prec_recall = compute_prdc(real_maps, generated_maps, nearest_k)\n",
        "        return mu1, sigma1, mu2, sigma2, prec_recall['precision'], prec_recall['recall']\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "1e2kvjQt8WTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate inception score for cifar-10 in Keras\n",
        "from math import floor\n",
        "from numpy import ones\n",
        "from numpy import expand_dims\n",
        "from numpy import log\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import exp\n",
        "from numpy.random import shuffle\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.datasets import cifar10\n",
        "from skimage.transform import resize\n",
        "from numpy import asarray\n",
        "\n",
        "# scale an array of images to a new size\n",
        "def scale_images(images, new_shape):\n",
        "\timages_list = list()\n",
        "\tfor image in images:\n",
        "\t\t# resize with nearest neighbor interpolation\n",
        "\t\tnew_image = resize(image, new_shape, 0)\n",
        "\t\t# store\n",
        "\t\timages_list.append(new_image)\n",
        "\treturn asarray(images_list)\n",
        "\n",
        "# assumes images have any shape and pixels in [0,255]\n",
        "def calculate_inception_score(images, n_split=10, eps=1E-16):\n",
        "\t# load inception v3 model\n",
        "\tmodel = InceptionV3()\n",
        "\t# enumerate splits of images/predictions\n",
        "\tscores = list()\n",
        "\tn_part = floor(images.shape[0] / n_split)\n",
        "\tfor i in range(n_split):\n",
        "\t\t# retrieve images\n",
        "\t\tix_start, ix_end = i * n_part, (i+1) * n_part\n",
        "\t\tsubset = images[ix_start:ix_end]\n",
        "\t\t# convert from uint8 to float32\n",
        "\t\tsubset = subset.astype('float32')\n",
        "\t\t# scale images to the required size\n",
        "\t\tsubset = scale_images(subset, (299,299,3))\n",
        "\t\t# pre-process images, scale to [-1,1]\n",
        "\t\tsubset = preprocess_input(subset)\n",
        "\t\t# predict p(y|x)\n",
        "\t\tp_yx = model.predict(subset)\n",
        "\t\t# calculate p(y)\n",
        "\t\tp_y = expand_dims(p_yx.mean(axis=0), 0)\n",
        "\t\t# calculate KL divergence using log probabilities\n",
        "\t\tkl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
        "\t\t# sum over classes\n",
        "\t\tsum_kl_d = kl_d.sum(axis=1)\n",
        "\t\t# average over images\n",
        "\t\tavg_kl_d = mean(sum_kl_d)\n",
        "\t\t# undo the log\n",
        "\t\tis_score = exp(avg_kl_d)\n",
        "\t\t# store\n",
        "\t\tscores.append(is_score)\n",
        "\t# average across images\n",
        "\tis_avg, is_std = mean(scores), std(scores)\n",
        "\treturn is_avg, is_std\n",
        "\"\"\"\n",
        "# load cifar10 images\n",
        "(images, _), (_, _) = cifar10.load_data()\n",
        "# shuffle images\n",
        "shuffle(images)\n",
        "print('loaded', images.shape)\n",
        "# calculate inception score\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Nendu8tsFAbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StyleGANTrainer:\n",
        "    def __init__(self):\n",
        "        self.style_depth = 8\n",
        "        self.in_channel = 256\n",
        "        self.out_channel = 128\n",
        "        self.latent_size = 160\n",
        "        self.blocks = 3\n",
        "        self.ngpu = 0\n",
        "        self.epochs = 6\n",
        "        self.learning_rate = 1e-3\n",
        "        self.beta = (0.0, 0.99)\n",
        "        self.batch_size = 64\n",
        "        self.img_channel = 3\n",
        "        self.min_res = 4\n",
        "        self.max_res = 28\n",
        "        self.kernel_size = 5\n",
        "        self.num_workers = 3\n",
        "        self.batch_part = 0.5\n",
        "        self.r1_interval = 16\n",
        "        self.pl_weight = 20\n",
        "        self.D_steps = 1\n",
        "        self.r1_weight = 8\n",
        "        self.pl_interval = 4\n",
        "        self.decay = 0.01\n",
        "        self.avg = 0\n",
        "        self.mean = 0\n",
        "        self.std = 0.0\n",
        "        self.eval = EvaluationMetric()\n",
        "        self.pl_batch = int(self.batch_part * self.batch_size)\n",
        "        self.train_dir = './train_generated'\n",
        "        self.train_dataloader = cifardata(self.batch_size, self.num_workers)\n",
        "        self.device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and self.ngpu>0) else \"cpu\")\n",
        "        self.Generator = Generator(self.in_channel, self.out_channel, self.kernel_size, self.latent_size,\n",
        "                                   self.style_depth, self.img_channel, self.min_res, self.max_res, self.blocks)\n",
        "        self.Generator = Equalized_Linear('weight')(self.Generator)\n",
        "\n",
        "        self.Discriminator = Discriminator(self.in_channel, self.out_channel, self.kernel_size, self.blocks,\n",
        "                                           self.img_channel, self.min_res, self.max_res)\n",
        "        self.Discriminator = Equalized_Linear('weight')(self.Discriminator)\n",
        "        self.optimizer_g = Adam(self.Generator.parameters(), lr=self.learning_rate, betas=self.beta)\n",
        "        self.optimizer_d = Adam(self.Discriminator.parameters(), lr=self.learning_rate, betas=self.beta)\n",
        "        self.writer = SummaryWriter('/content/drive/MyDrive/logs/StyleGAN/CIFAR10/logs')\n",
        "\n",
        "    def path_reg(self, dlatent, gen_out):\n",
        "        noise = torch.randn(gen_out.shape, device=gen_out.device) / np.sqrt(np.prod(gen_out.shape[2:]))\n",
        "        grads = torch.autograd.grad((gen_out * noise).sum(), dlatent, create_graph=True)[0]\n",
        "        lengths = torch.sqrt((grads ** 2).mean(2).sum(1))\n",
        "        self.avg = self.decay * torch.mean(lengths.detach()) + (1 - self.decay) * self.avg\n",
        "        return torch.mean((lengths - self.avg) ** 2)\n",
        "\n",
        "    def generator_loss(self, i):\n",
        "        dlatent = self.Generator.sample_dlatents(self.batch_size)\n",
        "        if i % self.pl_interval == 0:\n",
        "            dlatent_1, dlatent_2 = dlatent[:self.pl_batch], dlatent[self.pl_batch:]\n",
        "            fake_imgs = self.Generator.generate(torch.cat((dlatent_1, dlatent_2), 0))\n",
        "            fake_scores = self.Discriminator.get_score(fake_imgs)\n",
        "            g_loss = -F.logsigmoid(fake_scores).mean()\n",
        "            gen_loss = g_loss + self.pl_weight * self.pl_interval * self.path_reg(dlatent_1, fake_imgs[:self.pl_batch])\n",
        "        else:\n",
        "            fake_imgs = self.Generator.generate(dlatent)\n",
        "            fake_scores = self.Discriminator.get_score(fake_imgs)\n",
        "            gen_loss = -F.logsigmoid(fake_scores).mean()\n",
        "        self.optimizer_g.zero_grad()\n",
        "        gen_loss.backward()\n",
        "        self.optimizer_g.step()\n",
        "        self.Generator.update_avg_weights()\n",
        "\n",
        "        return gen_loss\n",
        "\n",
        "    def discriminator_loss(self, real_data, i, n_epoch):\n",
        "        real_data.requires_grad = True\n",
        "        fake_imgs = self.Generator.sample(real_data.shape[0])\n",
        "        real_scores = self.Discriminator.get_score(real_data)\n",
        "        fake_scores = self.Discriminator.get_score(fake_imgs)\n",
        "        disc_loss = torch.mean(-F.logsigmoid(real_scores) + F.softplus(fake_scores))\n",
        "        grads = torch.autograd.grad(real_scores.sum(), real_data, create_graph=True)[0]\n",
        "        r1_reg = torch.mean((grads ** 2).sum(dim=[1, 2, 3]))\n",
        "        if i % self.r1_interval == 0 and n_epoch == self.D_steps - 1:\n",
        "            disc_loss += self.r1_weight * self.r1_interval * r1_reg\n",
        "        real_data.requires_grad = False\n",
        "        self.optimizer_d.zero_grad()\n",
        "        disc_loss.backward()\n",
        "        self.optimizer_d.step()\n",
        "\n",
        "        return disc_loss, real_scores.mean().item(), fake_scores.mean().item()\n",
        "\n",
        "    def run(self, checkpoint=None):\n",
        "\n",
        "        if not os.path.exists('/content/drive/MyDrive/Generated_Images'):\n",
        "            os.mkdir('/content/drive/MyDrive/Generated_Images')\n",
        "\n",
        "        if not os.path.exists('/content/drive/MyDrive/checkpoints'):\n",
        "            os.mkdir('/content/drive/MyDrive/checkpoints')\n",
        "\n",
        "\n",
        "        if checkpoint:\n",
        "            self.load_checkpoint(checkpoint)\n",
        "        self.Generator.train()\n",
        "        self.Discriminator.train()\n",
        "\n",
        "        for i in tqdm(range(self.epochs)):\n",
        "            for n_epoch in range(self.D_steps):\n",
        "                real_data = next(self.train_dataloader)[0].to(self.device)\n",
        "                disc_loss, real_score, fake_score = self.discriminator_loss(real_data, i, n_epoch)\n",
        "\n",
        "            gen_loss = self.generator_loss(i)\n",
        "            gen = self.Generator.sample_images(64)\n",
        "\n",
        "            if i % 1 == 0:\n",
        "                print('Epoch:', i, 'Real Score:{:.4f}'.format(real_score), 'Fake Score:{:.4f}'.format(fake_score),\n",
        "                      'Generator Loss:{:.4f}'.format(gen_loss.item()),\n",
        "                      'Discriminator Loss:{:.4f}'.format(disc_loss.item()))\n",
        "                is_avg, is_std = calculate_inception_score(gen)\n",
        "                print('score', is_avg, is_std)\n",
        "                self.writer.add_scalar('Real Score', global_step=i, scalar_value=real_score)\n",
        "                self.writer.add_scalar('Fake Score', global_step=i, scalar_value=fake_score)\n",
        "                self.writer.add_scalar('Generator Loss', global_step=i, scalar_value=gen_loss.item())\n",
        "                self.writer.add_scalar('Discriminator Loss', global_step=i, scalar_value=disc_loss.item())\n",
        "                self.writer.close()\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                save_image(gen, '/content/drive/MyDrive/Generated_Images/Iter{}.png'.format(i))\n",
        "                # save_image(real_data, 'Real_Images/Real{}.png'.format(i))\n",
        "                self.eval.evaluate(real_data, gen)\n",
        "\n",
        "            if i % 500 == 0:\n",
        "                self.save_checkpoint(i)\n",
        "\n",
        "    def load_checkpoint(self, filename):\n",
        "        checkpoint = torch.load(filename)\n",
        "        self.Generator.load_state_dict(checkpoint['generator'])\n",
        "        self.Discriminator.load_state_dict(checkpoint['discriminator'])\n",
        "        self.optimizer_g.load_state_dict(checkpoint['generator_optimizer'])\n",
        "        self.optimizer_d.load_state_dict(checkpoint['discriminator_optimizer'])\n",
        "\n",
        "    def save_checkpoint(self, epoch):\n",
        "        torch.save({\n",
        "            'generator': self.Generator.state_dict(),\n",
        "            'discriminator': self.Discriminator.state_dict(),\n",
        "            'generator_optimizer': self.optimizer_g.state_dict(),\n",
        "            'discriminator_optimizer': self.optimizer_d.state_dict(),\n",
        "        }, '/content/drive/MyDrive/checkpoints/Model{}.pth'.format(epoch))\n"
      ],
      "metadata": {
        "id": "JMPh1d9l8el_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/logs/StyleGAN/CIFAR10/logs"
      ],
      "metadata": {
        "id": "QB785oAJ-58Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    train = StyleGANTrainer()\n",
        "    train.run()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    fire.Fire(main)"
      ],
      "metadata": {
        "id": "xBQanw59_BLO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}