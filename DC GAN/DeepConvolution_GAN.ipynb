{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "#from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import math\n",
        "import warnings\n",
        "import numpy as np\n",
        "from scipy import linalg\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "import time\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset  # For custom datasets\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "pYcEqoTahgOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to log the values of discriminator and generator loss using the weights and biases, a user account has to be created under **weights and biases** api."
      ],
      "metadata": {
        "id": "tpyJpEr2h8Dr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wd29m5KYu-m-"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -qU\n",
        "import wandb\n",
        "wandb.login()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb25rcfAu60G"
      },
      "outputs": [],
      "source": [
        "#Initialising weights and biases API to track generation ans=d discrimination losses\n",
        "\n",
        "wandb.init(project=\"DCGAN_Wano_1000epochs\",name='Loss_curve',config={\n",
        "      \"learning_rate\": 0.0002,\n",
        "      \"architecture\": \"DCGAN\",\n",
        "      \"dataset\": \"cifar\",\n",
        "      \"epochs\":n_epochs,\n",
        "      }) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBeiAIZUeLL8"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.init_size = img_size // 4\n",
        "        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.ReLU(0.2),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.ReLU(0.2),\n",
        "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.l1(z)\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
        "        img = self.conv_blocks(out)\n",
        "        return img\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\n",
        "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
        "            return block\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(channels, 16, bn=False),\n",
        "            *discriminator_block(16, 32),\n",
        "            *discriminator_block(32, 64),\n",
        "            *discriminator_block(64, 128),\n",
        "        )\n",
        "\n",
        "        # The height and width of downsampled image\n",
        "        ds_size = img_size // 2 ** 4\n",
        "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, img):\n",
        "        out = self.model(img)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        validity = self.adv_layer(out)\n",
        "\n",
        "        return validity\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7dd83DuihvTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"images\", exist_ok=True)\n",
        "\n",
        "n_epochs=1000  # number of epochs of training\n",
        "batch_size=64 # size of the batches\n",
        "lr=0.0002 # adam: learning rate\n",
        "b1=0.5  # adam: decay of first order momentum of gradient\n",
        "b2=0.999  # adam: decay of second order momentum of gradient\n",
        "n_cpu=8   #  number of cpu threads to use during batch generation\n",
        "latent_dim=100 #  dimensionality of the latent space\n",
        "img_size=32   # size of each image dimension\n",
        "channels=3    #number of image channels\n",
        "sample_interval=400 # interval between image sampling\n",
        "cuda = True if torch.cuda.is_available() else False"
      ],
      "metadata": {
        "id": "kpdg54jphvtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)"
      ],
      "metadata": {
        "id": "VpaL_xb7imsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights\n",
        "generator.apply(weights_init_normal)\n",
        "discriminator.apply(weights_init_normal)\n",
        "print(generator)\n",
        "print(discriminator)\n",
        "\n",
        "# Configure data loader\n",
        "os.makedirs(\"../../data/mnist\", exist_ok=True)\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    datasets.SVHN(\n",
        "        \"../../data/mnist\",split='train',\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])]\n",
        "        ),\n",
        "    ),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "'''\n",
        "# Uncomment the following to train GANs using CIFAR10 dataset\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10(\n",
        "        \"../../data/mnist\",train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])]\n",
        "        ),\n",
        "    ),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "1rl9KM25iYW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eX28EjKHgRuE"
      },
      "outputs": [],
      "source": [
        "# Loss function\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJpmbayAeSQx"
      },
      "outputs": [],
      "source": [
        "class FID():\n",
        "    \n",
        "    def __init__(self, cache_dir='./Cache',  device='cpu',transform_input=True):\n",
        "        os.environ[\"TORCH_HOME\"] = \"./Cache\"\n",
        "        self.device=device\n",
        "        self.transform_input = transform_input\n",
        "        self.InceptionV3 = models.inception_v3(pretrained=True, transform_input=False, aux_logits=True).to(device=self.device)\n",
        "        self.InceptionV3.eval()\n",
        "    \n",
        "    def build_maps(self, x):\n",
        "        # Resize to Fit InceptionV3\n",
        "        if list(x.shape[-2:]) != [299,299]:\n",
        "            with warnings.catch_warnings():\n",
        "                warnings.simplefilter(\"ignore\")\n",
        "                x = F.interpolate(x, size=[299,299], mode='bilinear')\n",
        "        # Transform Input to InceptionV3 Standards\n",
        "        if self.transform_input:\n",
        "            a = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
        "            b = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
        "            c = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
        "            x = torch.cat((a,b,c), 1)\n",
        "        # Run Through Partial InceptionV3 Model\n",
        "        with torch.no_grad():\n",
        "            # N x 3 x 299 x 299\n",
        "            x = self.InceptionV3.Conv2d_1a_3x3(x)\n",
        "            # N x 32 x 149 x 149\n",
        "            x = self.InceptionV3.Conv2d_2a_3x3(x)\n",
        "            # N x 32 x 147 x 147\n",
        "            x = self.InceptionV3.Conv2d_2b_3x3(x)\n",
        "            # N x 64 x 147 x 147\n",
        "            x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "            # N x 64 x 73 x 73\n",
        "            x = self.InceptionV3.Conv2d_3b_1x1(x)\n",
        "            # N x 80 x 73 x 73\n",
        "            x = self.InceptionV3.Conv2d_4a_3x3(x)\n",
        "            # N x 192 x 71 x 71\n",
        "            x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "            # N x 192 x 35 x 35\n",
        "            x = self.InceptionV3.Mixed_5b(x)\n",
        "            # N x 256 x 35 x 35\n",
        "            x = self.InceptionV3.Mixed_5c(x)\n",
        "            # N x 288 x 35 x 35\n",
        "            x = self.InceptionV3.Mixed_5d(x)\n",
        "            # N x 288 x 35 x 35\n",
        "            x = self.InceptionV3.Mixed_6a(x)\n",
        "            # N x 768 x 17 x 17\n",
        "            x = self.InceptionV3.Mixed_6b(x)\n",
        "            # N x 768 x 17 x 17\n",
        "            x = self.InceptionV3.Mixed_6c(x)\n",
        "            # N x 768 x 17 x 17\n",
        "            x = self.InceptionV3.Mixed_6d(x)\n",
        "            # N x 768 x 17 x 17\n",
        "            x = self.InceptionV3.Mixed_6e(x)\n",
        "            # N x 768 x 17 x 17\n",
        "            x = self.InceptionV3.Mixed_7a(x)\n",
        "            # N x 1280 x 8 x 8\n",
        "            x = self.InceptionV3.Mixed_7b(x)\n",
        "            # N x 2048 x 8 x 8\n",
        "            x = self.InceptionV3.Mixed_7c(x)\n",
        "            # N x 2048 x 8 x 8\n",
        "            # Adaptive average pooling\n",
        "            x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "            # N x 2048 x 1 x 1\n",
        "            return x\n",
        "  \n",
        "\n",
        "    def compute_fid(self, real_img, generated_img, batch_size=64):\n",
        "        # Ensure Set Sizes are the Same\n",
        "        assert(real_img.shape[0] == generated_img.shape[0])\n",
        "        # Build Random Sampling Orders\n",
        "        real_img = real_img[np.random.permutation(real_img.shape[0])]\n",
        "        generated_imag = generated_img[np.random.permutation(generated_img.shape[0])]\n",
        "        # Lists of Maps per Batch\n",
        "        real_maps = []\n",
        "        gen_maps = []\n",
        "        # Build Maps\n",
        "        for s in range(int(math.ceil(real_img.shape[0]/batch_size))):\n",
        "            sidx = np.arange(batch_size*s, min(batch_size*(s+1), real_img.shape[0]))\n",
        "            real_maps.append(self.build_maps(real_img[sidx].to(device=self.device)).detach().to(device='cpu'))\n",
        "            gen_maps.append(self.build_maps(generated_imag[sidx].to(device=self.device)).detach().to(device='cpu'))\n",
        "\n",
        "        # Concatenate Maps\n",
        "        real_maps = np.squeeze(torch.cat(real_maps).numpy())\n",
        "        gen_maps = np.squeeze(torch.cat(gen_maps).numpy())\n",
        "        # Calculate FID\n",
        "        # Activation Statistics\n",
        "        mu_g = np.mean(gen_maps, axis=0)\n",
        "        mu_x = np.mean(real_maps, axis=0)\n",
        "        sigma_g = np.cov(gen_maps, rowvar=False)\n",
        "        sigma_x = np.cov(real_maps, rowvar=False)\n",
        "        # Sum of Squared Differences\n",
        "        ssd = np.sum((mu_g - mu_x)**2)\n",
        "        # Square Root of Product of Covariances\n",
        "        covmean = linalg.sqrtm(sigma_g.dot(sigma_x), disp=False)[0]\n",
        "        if np.iscomplexobj(covmean):\n",
        "            covmean = covmean.real\n",
        "        # Final FID Computation\n",
        "        return ssd + np.trace(sigma_g + sigma_x - 2*covmean)\n",
        "\n",
        "fid_ = FID()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q03evLSweTj6"
      },
      "outputs": [],
      "source": [
        "#Training\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = generator(z)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Measure discriminator's ability to classify real from generated samples\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        if i%100==0:\n",
        "          print(\n",
        "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "            % (epoch, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
        "        )\n",
        "        wandb.log({\"Disc_loss\": d_loss.item(), \"Gen_loss\": g_loss.item()})\n",
        "        wandb.log({\"Mean_Disc_loss\": d_loss.mean().item(), \"Mean_Gen_loss\": g_loss.mean().item()})\n",
        "\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        if i==0:\n",
        "            vutils.save_image(gen_imgs,'/content/images/gen_images_epoch{}_samples{}.png'.format(epoch,i),normalize=True) \n",
        "            vutils.save_image(gen_imgs,'/content/drive/MyDrive/DC_GAN/Cifar_GenSamples/generated_images_epoch{}_samples{}.png'.format(epoch,i),normalize=True)\n",
        "            \n",
        "        if epoch==n_epochs-1 and i==0:\n",
        "            fid_val = fid_.compute_fid(real_imgs, gen_imgs)\n",
        "            print(fid_val)\n",
        "            with open(('/content/drive/MyDrive/DCGAN_fid_scores.txt'), 'a') as f:\n",
        "                f.write(f'{epoch},{fid_val}\\n')\n",
        "\n",
        "        if epoch%100==0 and i==0 and epoch>0:\n",
        "            fid_val = fid_.compute_fid(real_imgs, gen_imgs)\n",
        "            print(fid_val)\n",
        "            with open(('/content/drive/MyDrive/DCGAN_fid_scores.txt'), 'a') as f:\n",
        "                f.write(f'{epoch},{fid_val}\\n')\n",
        "          \n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}